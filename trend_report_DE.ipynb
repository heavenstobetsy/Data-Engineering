{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a33b06",
   "metadata": {},
   "source": [
    "### 1A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f30148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "def extract_song_data(file_path):\n",
    "    \n",
    "    #Load\n",
    "    wb = openpyxl.load_workbook(file_path)\n",
    "\n",
    "    #Sheet names for the Report Page N Results sheets\n",
    "    results_sheet_names = [sheet_name for sheet_name in wb.sheetnames if 'Report Page' in sheet_name]\n",
    "\n",
    "    rows_list = []\n",
    "    \n",
    "    #Loop through sheets\n",
    "    for sheet_name in results_sheet_names:\n",
    "        sheet = wb[sheet_name]\n",
    "        \n",
    "        #Create dictionary keys\n",
    "        headers = ['Artist', 'Song Name']\n",
    "        for row in sheet.iter_rows(min_row=12, min_col=1):\n",
    "            for col, header in zip(row, sheet[11]):\n",
    "                headers.append(header.value)\n",
    "            break  \n",
    "            \n",
    "        #Find the artist and song name\n",
    "        #A shortcut--it's not best practice to hardcode this. I would find this dynamically\n",
    "        artist = sheet['C2'].value\n",
    "        song_name = sheet['C3'].value\n",
    "        \n",
    "        #Loop through row for values\n",
    "        for row in sheet.iter_rows(min_row=12, min_col=1):\n",
    "            #Columns in each row\n",
    "            cols = []\n",
    "            for col in row:\n",
    "                cols.append(col.value)\n",
    "            \n",
    "            #Add cols to beginning\n",
    "            cols.insert(0, song_name)\n",
    "            cols.insert(0, artist)\n",
    "\n",
    "            rows_list.append(cols)\n",
    "    \n",
    "#Dataframe & cleanup: less efficient, but easier to adjust for analyst requirements\n",
    "    song_data = pd.DataFrame(rows_list, columns=headers)\n",
    "\n",
    "    #Relabel values in 'Activity' column\n",
    "    song_data['Activity'] = song_data['Activity'].replace({'Songs w/SES On-Demand': 'Consumption', 'Digital Song Sales': 'Sales','Streaming On-Demand Audio': 'Audio','Streaming On-Demand Video': 'Video'})\n",
    "    \n",
    "    #Remove 'ISRC/Barcode' column\n",
    "    song_data = song_data.drop('ISRC/Barcode', axis=1)\n",
    "    \n",
    "    #Select columns containing 'Week' & others needed for analysis below\n",
    "    song_data = pd.concat([song_data.filter(like='Week'), song_data[['Song Name', 'Artist', 'Activity','% Chg','YTD (11/22/2018)','ATD (11/22/2018)']]], axis=1)\n",
    "\n",
    "       \n",
    "    return song_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908c1d1",
   "metadata": {},
   "source": [
    "### 1B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ec4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "def compare_song_data(file_path):\n",
    "    \n",
    "    #Load\n",
    "    wb = openpyxl.load_workbook(file_path)\n",
    "\n",
    "    #Sheet names for the Report Page N Results sheets\n",
    "    results_sheet_names = [sheet_name for sheet_name in wb.sheetnames if 'Report Page' in sheet_name]\n",
    "\n",
    "    rows_list = []\n",
    "    \n",
    "    #Loop through sheets\n",
    "    for sheet_name in results_sheet_names:\n",
    "        sheet = wb[sheet_name]\n",
    "        \n",
    "        #Create dictionary keys\n",
    "        headers = ['Artist', 'Song Name']\n",
    "        for row in sheet.iter_rows(min_row=12, min_col=1):\n",
    "            for col, header in zip(row, sheet[11]):\n",
    "                headers.append(header.value)\n",
    "            break  \n",
    "            \n",
    "        #Find the artist and song name\n",
    "        #A shortcut--it's not best practice to hardcode this. I would find this dynamically\n",
    "        artist = sheet['C2'].value\n",
    "        song_name = sheet['C3'].value\n",
    "        \n",
    "        #Loop through row for values\n",
    "        for row in sheet.iter_rows(min_row=12, min_col=1):\n",
    "            #Columns in each row\n",
    "            cols = []\n",
    "            for col in row:\n",
    "                cols.append(col.value)\n",
    "            \n",
    "            #Add cols to beginning\n",
    "            cols.insert(0, song_name)\n",
    "            cols.insert(0, artist)\n",
    "\n",
    "            rows_list.append(cols)\n",
    "    \n",
    "#Dataframe & cleanup: less efficient, but easier to adjust for analyst requirements\n",
    "    song_data = pd.DataFrame(rows_list, columns=headers)\n",
    "\n",
    "    #Relabel values in 'Activity' column\n",
    "    song_data['Activity'] = song_data['Activity'].replace({'Songs w/SES On-Demand': 'Consumption', 'Digital Song Sales': 'Sales','Streaming On-Demand Audio': 'Audio','Streaming On-Demand Video': 'Video'})\n",
    "    \n",
    "    #Remove 'ISRC/Barcode' column\n",
    "    song_data = song_data.drop('ISRC/Barcode', axis=1)\n",
    "    \n",
    "    #Select columns containing 'Week' & others needed for analysis below\n",
    "    song_data = pd.concat([song_data.filter(like='Week'), song_data[['Song Name', 'Artist','Activity','% Chg','YTD (11/22/2018)','ATD (11/22/2018)']]], axis=1)\n",
    "\n",
    "#Entity Selection\n",
    "\n",
    "    song_names = song_data['Song Name'].unique().tolist()\n",
    "    song_artists = song_data['Artist'].unique().tolist()  \n",
    "\n",
    "    #Get the song list from the Report Summary\n",
    "    report_song_list = []\n",
    "    summary_sheet = wb['Report Summary']\n",
    "\n",
    "    #Clean\n",
    "    #A shortcut--it's not best practice to hardcode this. I would find this dynamically\n",
    "    songs = summary_sheet['b4'].value\n",
    "    for song_info in songs.split('\\n'):\n",
    "        song_info_parts = song_info.split(\"(Artist:\")\n",
    "        song_name = song_info_parts[0].replace(\"Song: \", \"\").strip()\n",
    "        artist_name = song_info_parts[1].replace(\")\", \"\").strip()\n",
    "\n",
    "        if song_name in song_names and artist_name not in song_artists:\n",
    "            print(\"Warning:\", song_name, \"by\", artist_name, \"is NOT in the song_data.\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19d7f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Audio by LSD (Labrinth/Sia/Diplo is NOT in the song_data.\n",
      "Warning: Cherry Cola by Kuwada is NOT in the song_data.\n",
      "Warning: Strip by Little Mix is NOT in the song_data.\n"
     ]
    }
   ],
   "source": [
    "compare_song_data(file_path='Trend Report Sample.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe96436",
   "metadata": {},
   "source": [
    "### 1C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a395f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_song_data(file_path='Trend Report Sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d66650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of audio streams for the current week is: 394677.9\n"
     ]
    }
   ],
   "source": [
    "#What is the average number of audio streams for the current week in this set of songs?\n",
    "\n",
    "#Activity='Audio'\n",
    "audio_data= df[(df['Activity'] == 'Audio')]\n",
    "\n",
    "#Avg for current week\n",
    "avg_sales= audio_data['Week 47 2018 11/16/2018 - 11/22/2018'].mean()\n",
    "\n",
    "print('The average number of audio streams for the current week is:', avg_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e7d794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The track has the 2nd highest consumption for the current week is: Sit Next To Me\n"
     ]
    }
   ],
   "source": [
    "#Which track has the 2nd highest consumption for the current week?\n",
    "\n",
    "#Activity='Consumption'\n",
    "consumption_data= df[(df['Activity'] == 'Consumption')]\n",
    "\n",
    "#2nd highest value for current week\n",
    "second_highest= consumption_data['Week 47 2018 11/16/2018 - 11/22/2018'].nlargest(2).iloc[-1]\n",
    "\n",
    "#Song name\n",
    "song_name= df.loc[df['Week 47 2018 11/16/2018 - 11/22/2018'] == second_highest, 'Song Name'].iloc[0]\n",
    "\n",
    "print('The track has the 2nd highest consumption for the current week is:', song_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf8197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For One Kiss, % Video/Consumption is: 17.88\n"
     ]
    }
   ],
   "source": [
    "#A simplified consumption formula is Consumption = Sales + Audio/125 + Video/375.  \n",
    "#For the song One Kissâ€™ activity-to-date data, Video accounts for what percentage of Consumption?\n",
    "\n",
    "#Song='One Kiss'\n",
    "one_kiss_data= df[(df['Song Name'] == 'One Kiss')]\n",
    "\n",
    "#Activity='Video' & 'Consumption'\n",
    "one_kiss_video_data= one_kiss_data.loc[(one_kiss_data['Activity'] == 'Video')]\n",
    "one_kiss_con_data= one_kiss_data.loc[(one_kiss_data['Activity'] == 'Consumption')]\n",
    "\n",
    "#Calc\n",
    "consump = one_kiss_con_data['ATD (11/22/2018)'].sum()\n",
    "vid_sum= one_kiss_video_data['ATD (11/22/2018)'].sum()\n",
    "percent= round((vid_sum/375)/consump*100, 2)\n",
    "\n",
    "print('For One Kiss, % Video/Consumption is:',percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af95b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song names: ['Audio', 'Cherry Cola', 'One Kiss', 'Sit Next To Me', 'Strip', 'The Flute Song']\n"
     ]
    }
   ],
   "source": [
    "#Which tracks increased their video streams by greater than 3% in the current week as compared to the previous week?\n",
    "\n",
    "#Activity='Video'\n",
    "video_data= df[(df['Activity'] == 'Video')]\n",
    "\n",
    "#Sum video streams, group by current & last week\n",
    "week_sum_by_song= video_data.groupby('Song Name')[['Week 46 2018 11/09/2018 - 11/15/2018', 'Week 47 2018 11/16/2018 - 11/22/2018']].sum()\n",
    "\n",
    "#Filter to only include rows where current week> 3%\n",
    "filtered_data= week_sum_by_song[(week_sum_by_song['Week 47 2018 11/16/2018 - 11/22/2018'] / week_sum_by_song['Week 46 2018 11/09/2018 - 11/15/2018'] > 0.03)]\n",
    "\n",
    "#Song Names\n",
    "print('Song names:', filtered_data.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf915e5",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4de1f",
   "metadata": {},
   "source": [
    "    In the long term, if data providers are open to feedback about changing their song metadata, establishing a standardized naming convention for music data would be the ideal solution. However, for the short term, \n",
    "    there are a few ways to improve matches:\n",
    "\n",
    "    *ISRC/Barcode: \n",
    "        The trend report sample had an ISRC/Barcode column. If this is a unique identifier, it can be used to \n",
    "        connect songs and artists without data cleaning and matching. After joining using these identifiers, it \n",
    "        would be easier to clean song/artist data knowing there is already a match. Concurrently, with this, I \n",
    "        would use a database.\n",
    "    *SQL Database: \n",
    "        Retrieve the song/artist combinations from each site's API/other source of data, and store them in \n",
    "        separate lists or data structures. Create a table for each site that contains columns for the artist \n",
    "        name, song title, and any other relevant metadata. ISRC/Barcodes would be useful for this, but if that \n",
    "        is not available, develop a standardized naming convention that can be used and applied.\t\n",
    "    *Standardization: \n",
    "        Develop a set of rules or algorithms to match the artist/title combinations across different data sites.\n",
    "        Ideally, data coming from Amazon, Apple, and Spotify has its own set of custom rules, however, Tiktok \n",
    "        and Youtube likely need a more complex set of rules due to live performances, leaked songs, \n",
    "        official/unofficial releases by individuals other than one corporation. Possible ways to standardize \n",
    "        would include: converting all characters to lowercase, remove special characters and spaces and \n",
    "        standardize them with an underscore/hyphen, trim unneeded words, standardize titles (Mrs, Mr) and\n",
    "        different spellings (UK vs US).\n",
    "    *Python libraries: \n",
    "        There are a couple Python libraries that can help with comparing titlesâ€“Iâ€™ve used fuzzywuzzy in the \n",
    "        past, which calculates a similarity score for two given strings.\n",
    "    *Machine learning/similarity scores:\n",
    "        Compare songs and artists based on their similarity scores.  I have extensive experience with this, as \n",
    "        I have developed and led projects that needed standardizing for job titles, company names, and \n",
    "        industries while working for Indeed.  I have built machine learning algorithms that are trained on large \n",
    "        datasets that assign a confidence score to each match based on their similarity score. A threshold is \n",
    "        used to filter out matches that fall below a certain level of confidence. Over time, an algorithm can \n",
    "        learn from past matches and continuously improve its matching capabilities over time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42304761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
